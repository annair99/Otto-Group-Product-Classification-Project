{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer   \n",
    "from sklearn.metrics import confusion_matrix, classification_report, log_loss\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2idx = {\n",
    "    'Class_1':0,\n",
    "    'Class_2':1,\n",
    "    'Class_3':2,\n",
    "    'Class_4':3,\n",
    "    'Class_5':4,\n",
    "    'Class_6':5,\n",
    "    'Class_7':6,\n",
    "    'Class_8':7,\n",
    "    'Class_9':8,\n",
    "}\n",
    "\n",
    "idx2class = {v: k for k, v in class2idx.items()}\n",
    "\n",
    "train['target'].replace(class2idx, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train.iloc[:, 1:94])\n",
    "y = np.array(train.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_test = test.iloc[:, 1:94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = FunctionTransformer(np.log1p, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training set on full data\n",
    "y_full = y\n",
    "X_full = transformer.fit_transform(X)\n",
    "### Full dataset\n",
    "full_dataset = ClassifierDataset(torch.from_numpy(X_full).float(), torch.from_numpy(y_full).long())\n",
    "### Test dataset\n",
    "X_final_test = transformer.fit_transform(X_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierDataset_test(Dataset):\n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "test_dataset = ClassifierDataset_test(torch.from_numpy(X_final_test).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 35\n",
    "batch_size = 128 #128\n",
    "LEARNING_RATE = 0.03923132744309443\n",
    "NUM_FEATURES = 93 #len(X.columns)\n",
    "NUM_CLASSES = 9\n",
    "MOMENT = 0.5158575830025897"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff747801dc340ecab3849bb88bd84bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f5d88f4beb46aa9db6621466566429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.749 | Train Acc: 72.711\n",
      "Epoch 002: | Train Loss: 0.620 | Train Acc: 76.146\n",
      "Epoch 003: | Train Loss: 0.591 | Train Acc: 77.316\n",
      "Epoch 004: | Train Loss: 0.573 | Train Acc: 77.937\n",
      "Epoch 005: | Train Loss: 0.555 | Train Acc: 78.453\n",
      "Epoch 006: | Train Loss: 0.545 | Train Acc: 78.706\n",
      "Epoch 007: | Train Loss: 0.535 | Train Acc: 78.987\n",
      "Epoch 008: | Train Loss: 0.527 | Train Acc: 79.521\n",
      "Epoch 009: | Train Loss: 0.519 | Train Acc: 79.602\n",
      "Epoch 010: | Train Loss: 0.513 | Train Acc: 79.814\n",
      "Epoch 011: | Train Loss: 0.508 | Train Acc: 80.110\n",
      "Epoch 012: | Train Loss: 0.501 | Train Acc: 80.290\n",
      "Epoch 013: | Train Loss: 0.494 | Train Acc: 80.319\n",
      "Epoch 014: | Train Loss: 0.489 | Train Acc: 80.615\n",
      "Epoch 015: | Train Loss: 0.486 | Train Acc: 80.825\n",
      "Epoch 016: | Train Loss: 0.482 | Train Acc: 81.004\n",
      "Epoch 017: | Train Loss: 0.478 | Train Acc: 80.940\n",
      "Epoch 018: | Train Loss: 0.475 | Train Acc: 81.156\n",
      "Epoch 019: | Train Loss: 0.472 | Train Acc: 81.162\n",
      "Epoch 020: | Train Loss: 0.466 | Train Acc: 81.485\n",
      "Epoch 021: | Train Loss: 0.464 | Train Acc: 81.506\n",
      "Epoch 022: | Train Loss: 0.460 | Train Acc: 81.721\n",
      "Epoch 023: | Train Loss: 0.458 | Train Acc: 81.808\n",
      "Epoch 024: | Train Loss: 0.457 | Train Acc: 81.773\n",
      "Epoch 025: | Train Loss: 0.454 | Train Acc: 81.911\n",
      "Epoch 026: | Train Loss: 0.451 | Train Acc: 81.829\n",
      "Epoch 027: | Train Loss: 0.445 | Train Acc: 82.145\n",
      "Epoch 028: | Train Loss: 0.448 | Train Acc: 82.092\n",
      "Epoch 029: | Train Loss: 0.444 | Train Acc: 82.160\n",
      "Epoch 030: | Train Loss: 0.439 | Train Acc: 82.181\n",
      "Epoch 031: | Train Loss: 0.437 | Train Acc: 82.532\n",
      "Epoch 032: | Train Loss: 0.432 | Train Acc: 82.501\n",
      "Epoch 033: | Train Loss: 0.435 | Train Acc: 82.592\n",
      "Epoch 034: | Train Loss: 0.434 | Train Acc: 82.608\n",
      "Epoch 035: | Train Loss: 0.431 | Train Acc: 82.717\n",
      "Begin training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-75860f155e9b>:108: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  test_prediction = np.array(y_pred_list)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4dded0dea4942f8986698734e085ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.750 | Train Acc: 72.556\n",
      "Epoch 002: | Train Loss: 0.621 | Train Acc: 76.318\n",
      "Epoch 003: | Train Loss: 0.592 | Train Acc: 77.167\n",
      "Epoch 004: | Train Loss: 0.572 | Train Acc: 77.858\n",
      "Epoch 005: | Train Loss: 0.558 | Train Acc: 78.174\n",
      "Epoch 006: | Train Loss: 0.545 | Train Acc: 78.775\n",
      "Epoch 007: | Train Loss: 0.536 | Train Acc: 79.072\n",
      "Epoch 008: | Train Loss: 0.527 | Train Acc: 79.315\n",
      "Epoch 009: | Train Loss: 0.520 | Train Acc: 79.548\n",
      "Epoch 010: | Train Loss: 0.511 | Train Acc: 79.935\n",
      "Epoch 011: | Train Loss: 0.506 | Train Acc: 80.034\n",
      "Epoch 012: | Train Loss: 0.503 | Train Acc: 80.367\n",
      "Epoch 013: | Train Loss: 0.498 | Train Acc: 80.383\n",
      "Epoch 014: | Train Loss: 0.490 | Train Acc: 80.590\n",
      "Epoch 015: | Train Loss: 0.489 | Train Acc: 80.515\n",
      "Epoch 016: | Train Loss: 0.482 | Train Acc: 80.922\n",
      "Epoch 017: | Train Loss: 0.480 | Train Acc: 80.798\n",
      "Epoch 018: | Train Loss: 0.476 | Train Acc: 81.086\n",
      "Epoch 019: | Train Loss: 0.471 | Train Acc: 81.210\n",
      "Epoch 020: | Train Loss: 0.469 | Train Acc: 81.308\n",
      "Epoch 021: | Train Loss: 0.465 | Train Acc: 81.564\n",
      "Epoch 022: | Train Loss: 0.461 | Train Acc: 81.711\n",
      "Epoch 023: | Train Loss: 0.457 | Train Acc: 81.747\n",
      "Epoch 024: | Train Loss: 0.458 | Train Acc: 81.771\n",
      "Epoch 025: | Train Loss: 0.453 | Train Acc: 81.878\n",
      "Epoch 026: | Train Loss: 0.451 | Train Acc: 81.930\n",
      "Epoch 027: | Train Loss: 0.447 | Train Acc: 82.157\n",
      "Epoch 028: | Train Loss: 0.443 | Train Acc: 82.331\n",
      "Epoch 029: | Train Loss: 0.445 | Train Acc: 82.196\n",
      "Epoch 030: | Train Loss: 0.439 | Train Acc: 82.412\n",
      "Epoch 031: | Train Loss: 0.437 | Train Acc: 82.460\n",
      "Epoch 032: | Train Loss: 0.437 | Train Acc: 82.452\n",
      "Epoch 033: | Train Loss: 0.433 | Train Acc: 82.565\n",
      "Epoch 034: | Train Loss: 0.432 | Train Acc: 82.421\n",
      "Epoch 035: | Train Loss: 0.429 | Train Acc: 82.791\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336429c6bde54aedb7c19007d8b2ce51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.747 | Train Acc: 72.870\n",
      "Epoch 002: | Train Loss: 0.623 | Train Acc: 76.194\n",
      "Epoch 003: | Train Loss: 0.592 | Train Acc: 77.261\n",
      "Epoch 004: | Train Loss: 0.573 | Train Acc: 77.858\n",
      "Epoch 005: | Train Loss: 0.559 | Train Acc: 78.264\n",
      "Epoch 006: | Train Loss: 0.547 | Train Acc: 78.414\n",
      "Epoch 007: | Train Loss: 0.537 | Train Acc: 78.916\n",
      "Epoch 008: | Train Loss: 0.531 | Train Acc: 79.076\n",
      "Epoch 009: | Train Loss: 0.523 | Train Acc: 79.406\n",
      "Epoch 010: | Train Loss: 0.516 | Train Acc: 79.577\n",
      "Epoch 011: | Train Loss: 0.508 | Train Acc: 79.863\n",
      "Epoch 012: | Train Loss: 0.504 | Train Acc: 80.076\n",
      "Epoch 013: | Train Loss: 0.499 | Train Acc: 80.287\n",
      "Epoch 014: | Train Loss: 0.493 | Train Acc: 80.464\n",
      "Epoch 015: | Train Loss: 0.489 | Train Acc: 80.608\n",
      "Epoch 016: | Train Loss: 0.485 | Train Acc: 80.589\n",
      "Epoch 017: | Train Loss: 0.480 | Train Acc: 80.738\n",
      "Epoch 018: | Train Loss: 0.477 | Train Acc: 81.048\n",
      "Epoch 019: | Train Loss: 0.472 | Train Acc: 81.022\n",
      "Epoch 020: | Train Loss: 0.469 | Train Acc: 81.330\n",
      "Epoch 021: | Train Loss: 0.468 | Train Acc: 81.228\n",
      "Epoch 022: | Train Loss: 0.461 | Train Acc: 81.485\n",
      "Epoch 023: | Train Loss: 0.458 | Train Acc: 81.705\n",
      "Epoch 024: | Train Loss: 0.456 | Train Acc: 81.728\n",
      "Epoch 025: | Train Loss: 0.453 | Train Acc: 81.714\n",
      "Epoch 026: | Train Loss: 0.450 | Train Acc: 81.937\n",
      "Epoch 027: | Train Loss: 0.449 | Train Acc: 81.982\n",
      "Epoch 028: | Train Loss: 0.445 | Train Acc: 82.067\n",
      "Epoch 029: | Train Loss: 0.446 | Train Acc: 82.019\n",
      "Epoch 030: | Train Loss: 0.443 | Train Acc: 82.272\n",
      "Epoch 031: | Train Loss: 0.438 | Train Acc: 82.569\n",
      "Epoch 032: | Train Loss: 0.438 | Train Acc: 82.489\n",
      "Epoch 033: | Train Loss: 0.433 | Train Acc: 82.533\n",
      "Epoch 034: | Train Loss: 0.434 | Train Acc: 82.453\n",
      "Epoch 035: | Train Loss: 0.429 | Train Acc: 82.671\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e446f5ea13844e9b4dd07df54ca25ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.748 | Train Acc: 72.692\n",
      "Epoch 002: | Train Loss: 0.622 | Train Acc: 76.080\n",
      "Epoch 003: | Train Loss: 0.591 | Train Acc: 77.095\n",
      "Epoch 004: | Train Loss: 0.570 | Train Acc: 77.891\n",
      "Epoch 005: | Train Loss: 0.557 | Train Acc: 78.498\n",
      "Epoch 006: | Train Loss: 0.545 | Train Acc: 78.652\n",
      "Epoch 007: | Train Loss: 0.535 | Train Acc: 79.085\n",
      "Epoch 008: | Train Loss: 0.529 | Train Acc: 79.364\n",
      "Epoch 009: | Train Loss: 0.522 | Train Acc: 79.574\n",
      "Epoch 010: | Train Loss: 0.514 | Train Acc: 79.819\n",
      "Epoch 011: | Train Loss: 0.508 | Train Acc: 80.005\n",
      "Epoch 012: | Train Loss: 0.502 | Train Acc: 80.001\n",
      "Epoch 013: | Train Loss: 0.498 | Train Acc: 80.204\n",
      "Epoch 014: | Train Loss: 0.493 | Train Acc: 80.535\n",
      "Epoch 015: | Train Loss: 0.485 | Train Acc: 80.760\n",
      "Epoch 016: | Train Loss: 0.481 | Train Acc: 80.883\n",
      "Epoch 017: | Train Loss: 0.479 | Train Acc: 80.896\n",
      "Epoch 018: | Train Loss: 0.475 | Train Acc: 80.998\n",
      "Epoch 019: | Train Loss: 0.472 | Train Acc: 81.278\n",
      "Epoch 020: | Train Loss: 0.469 | Train Acc: 81.153\n",
      "Epoch 021: | Train Loss: 0.466 | Train Acc: 81.334\n",
      "Epoch 022: | Train Loss: 0.462 | Train Acc: 81.448\n",
      "Epoch 023: | Train Loss: 0.457 | Train Acc: 81.777\n",
      "Epoch 024: | Train Loss: 0.457 | Train Acc: 81.768\n",
      "Epoch 025: | Train Loss: 0.452 | Train Acc: 81.872\n",
      "Epoch 026: | Train Loss: 0.450 | Train Acc: 81.849\n",
      "Epoch 027: | Train Loss: 0.445 | Train Acc: 82.104\n",
      "Epoch 028: | Train Loss: 0.441 | Train Acc: 82.312\n",
      "Epoch 029: | Train Loss: 0.441 | Train Acc: 82.393\n",
      "Epoch 030: | Train Loss: 0.443 | Train Acc: 82.274\n",
      "Epoch 031: | Train Loss: 0.440 | Train Acc: 82.338\n",
      "Epoch 032: | Train Loss: 0.435 | Train Acc: 82.505\n",
      "Epoch 033: | Train Loss: 0.434 | Train Acc: 82.490\n",
      "Epoch 034: | Train Loss: 0.431 | Train Acc: 82.641\n",
      "Epoch 035: | Train Loss: 0.430 | Train Acc: 82.795\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbf70b9cdab4ad18fd06360e127f864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.748 | Train Acc: 72.737\n",
      "Epoch 002: | Train Loss: 0.621 | Train Acc: 76.342\n",
      "Epoch 003: | Train Loss: 0.593 | Train Acc: 77.195\n",
      "Epoch 004: | Train Loss: 0.570 | Train Acc: 78.026\n",
      "Epoch 005: | Train Loss: 0.558 | Train Acc: 78.382\n",
      "Epoch 006: | Train Loss: 0.546 | Train Acc: 78.668\n",
      "Epoch 007: | Train Loss: 0.535 | Train Acc: 79.130\n",
      "Epoch 008: | Train Loss: 0.529 | Train Acc: 79.343\n",
      "Epoch 009: | Train Loss: 0.520 | Train Acc: 79.449\n",
      "Epoch 010: | Train Loss: 0.513 | Train Acc: 79.792\n",
      "Epoch 011: | Train Loss: 0.508 | Train Acc: 79.954\n",
      "Epoch 012: | Train Loss: 0.503 | Train Acc: 80.090\n",
      "Epoch 013: | Train Loss: 0.497 | Train Acc: 80.350\n",
      "Epoch 014: | Train Loss: 0.494 | Train Acc: 80.424\n",
      "Epoch 015: | Train Loss: 0.489 | Train Acc: 80.590\n",
      "Epoch 016: | Train Loss: 0.485 | Train Acc: 80.835\n",
      "Epoch 017: | Train Loss: 0.478 | Train Acc: 80.855\n",
      "Epoch 018: | Train Loss: 0.477 | Train Acc: 80.985\n",
      "Epoch 019: | Train Loss: 0.472 | Train Acc: 81.287\n",
      "Epoch 020: | Train Loss: 0.468 | Train Acc: 81.275\n",
      "Epoch 021: | Train Loss: 0.465 | Train Acc: 81.534\n",
      "Epoch 022: | Train Loss: 0.463 | Train Acc: 81.547\n",
      "Epoch 023: | Train Loss: 0.460 | Train Acc: 81.494\n",
      "Epoch 024: | Train Loss: 0.456 | Train Acc: 81.833\n",
      "Epoch 025: | Train Loss: 0.455 | Train Acc: 81.720\n",
      "Epoch 026: | Train Loss: 0.451 | Train Acc: 81.915\n",
      "Epoch 027: | Train Loss: 0.447 | Train Acc: 82.143\n",
      "Epoch 028: | Train Loss: 0.446 | Train Acc: 82.123\n",
      "Epoch 029: | Train Loss: 0.443 | Train Acc: 82.183\n",
      "Epoch 030: | Train Loss: 0.443 | Train Acc: 82.414\n",
      "Epoch 031: | Train Loss: 0.441 | Train Acc: 82.289\n",
      "Epoch 032: | Train Loss: 0.438 | Train Acc: 82.477\n",
      "Epoch 033: | Train Loss: 0.433 | Train Acc: 82.370\n",
      "Epoch 034: | Train Loss: 0.429 | Train Acc: 82.743\n",
      "Epoch 035: | Train Loss: 0.430 | Train Acc: 82.811\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2a1ecf2785487186c37eb7bfa1af32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.754 | Train Acc: 72.638\n",
      "Epoch 002: | Train Loss: 0.621 | Train Acc: 76.217\n",
      "Epoch 003: | Train Loss: 0.593 | Train Acc: 77.190\n",
      "Epoch 004: | Train Loss: 0.573 | Train Acc: 77.754\n",
      "Epoch 005: | Train Loss: 0.560 | Train Acc: 78.137\n",
      "Epoch 006: | Train Loss: 0.546 | Train Acc: 78.708\n",
      "Epoch 007: | Train Loss: 0.535 | Train Acc: 79.092\n",
      "Epoch 008: | Train Loss: 0.527 | Train Acc: 79.331\n",
      "Epoch 009: | Train Loss: 0.521 | Train Acc: 79.632\n",
      "Epoch 010: | Train Loss: 0.512 | Train Acc: 79.908\n",
      "Epoch 011: | Train Loss: 0.507 | Train Acc: 80.176\n",
      "Epoch 012: | Train Loss: 0.502 | Train Acc: 80.226\n",
      "Epoch 013: | Train Loss: 0.499 | Train Acc: 80.302\n",
      "Epoch 014: | Train Loss: 0.494 | Train Acc: 80.594\n",
      "Epoch 015: | Train Loss: 0.486 | Train Acc: 80.613\n",
      "Epoch 016: | Train Loss: 0.483 | Train Acc: 80.874\n",
      "Epoch 017: | Train Loss: 0.480 | Train Acc: 80.974\n",
      "Epoch 018: | Train Loss: 0.477 | Train Acc: 80.996\n",
      "Epoch 019: | Train Loss: 0.475 | Train Acc: 81.019\n",
      "Epoch 020: | Train Loss: 0.471 | Train Acc: 81.191\n",
      "Epoch 021: | Train Loss: 0.465 | Train Acc: 81.481\n",
      "Epoch 022: | Train Loss: 0.462 | Train Acc: 81.626\n",
      "Epoch 023: | Train Loss: 0.461 | Train Acc: 81.626\n",
      "Epoch 024: | Train Loss: 0.455 | Train Acc: 81.811\n",
      "Epoch 025: | Train Loss: 0.454 | Train Acc: 81.913\n",
      "Epoch 026: | Train Loss: 0.448 | Train Acc: 82.103\n",
      "Epoch 027: | Train Loss: 0.449 | Train Acc: 82.004\n",
      "Epoch 028: | Train Loss: 0.444 | Train Acc: 82.257\n",
      "Epoch 029: | Train Loss: 0.441 | Train Acc: 82.212\n",
      "Epoch 030: | Train Loss: 0.439 | Train Acc: 82.259\n",
      "Epoch 031: | Train Loss: 0.438 | Train Acc: 82.402\n",
      "Epoch 032: | Train Loss: 0.434 | Train Acc: 82.614\n",
      "Epoch 033: | Train Loss: 0.432 | Train Acc: 82.576\n",
      "Epoch 034: | Train Loss: 0.432 | Train Acc: 82.549\n",
      "Epoch 035: | Train Loss: 0.428 | Train Acc: 82.837\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634329ec76f24209b823a3ce7755a043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.755 | Train Acc: 72.637\n",
      "Epoch 002: | Train Loss: 0.624 | Train Acc: 76.133\n",
      "Epoch 003: | Train Loss: 0.593 | Train Acc: 77.121\n",
      "Epoch 004: | Train Loss: 0.573 | Train Acc: 77.705\n",
      "Epoch 005: | Train Loss: 0.561 | Train Acc: 78.096\n",
      "Epoch 006: | Train Loss: 0.550 | Train Acc: 78.363\n",
      "Epoch 007: | Train Loss: 0.538 | Train Acc: 78.892\n",
      "Epoch 008: | Train Loss: 0.533 | Train Acc: 79.071\n",
      "Epoch 009: | Train Loss: 0.522 | Train Acc: 79.608\n",
      "Epoch 010: | Train Loss: 0.515 | Train Acc: 79.706\n",
      "Epoch 011: | Train Loss: 0.510 | Train Acc: 79.973\n",
      "Epoch 012: | Train Loss: 0.504 | Train Acc: 80.104\n",
      "Epoch 013: | Train Loss: 0.497 | Train Acc: 80.346\n",
      "Epoch 014: | Train Loss: 0.493 | Train Acc: 80.500\n",
      "Epoch 015: | Train Loss: 0.490 | Train Acc: 80.469\n",
      "Epoch 016: | Train Loss: 0.483 | Train Acc: 80.830\n",
      "Epoch 017: | Train Loss: 0.480 | Train Acc: 81.024\n",
      "Epoch 018: | Train Loss: 0.475 | Train Acc: 81.125\n",
      "Epoch 019: | Train Loss: 0.472 | Train Acc: 81.354\n",
      "Epoch 020: | Train Loss: 0.469 | Train Acc: 81.177\n",
      "Epoch 021: | Train Loss: 0.464 | Train Acc: 81.394\n",
      "Epoch 022: | Train Loss: 0.462 | Train Acc: 81.481\n",
      "Epoch 023: | Train Loss: 0.461 | Train Acc: 81.462\n",
      "Epoch 024: | Train Loss: 0.456 | Train Acc: 81.776\n",
      "Epoch 025: | Train Loss: 0.454 | Train Acc: 81.861\n",
      "Epoch 026: | Train Loss: 0.451 | Train Acc: 81.916\n",
      "Epoch 027: | Train Loss: 0.448 | Train Acc: 82.117\n",
      "Epoch 028: | Train Loss: 0.447 | Train Acc: 82.117\n",
      "Epoch 029: | Train Loss: 0.440 | Train Acc: 82.396\n",
      "Epoch 030: | Train Loss: 0.442 | Train Acc: 82.191\n",
      "Epoch 031: | Train Loss: 0.438 | Train Acc: 82.448\n",
      "Epoch 032: | Train Loss: 0.437 | Train Acc: 82.259\n",
      "Epoch 033: | Train Loss: 0.435 | Train Acc: 82.575\n",
      "Epoch 034: | Train Loss: 0.432 | Train Acc: 82.527\n",
      "Epoch 035: | Train Loss: 0.430 | Train Acc: 82.689\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3260ba542d4e5aa5502739144639c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.751 | Train Acc: 72.565\n",
      "Epoch 002: | Train Loss: 0.621 | Train Acc: 76.338\n",
      "Epoch 003: | Train Loss: 0.594 | Train Acc: 77.146\n",
      "Epoch 004: | Train Loss: 0.575 | Train Acc: 77.517\n",
      "Epoch 005: | Train Loss: 0.558 | Train Acc: 78.263\n",
      "Epoch 006: | Train Loss: 0.546 | Train Acc: 78.594\n",
      "Epoch 007: | Train Loss: 0.534 | Train Acc: 79.058\n",
      "Epoch 008: | Train Loss: 0.528 | Train Acc: 79.273\n",
      "Epoch 009: | Train Loss: 0.519 | Train Acc: 79.556\n",
      "Epoch 010: | Train Loss: 0.515 | Train Acc: 79.832\n",
      "Epoch 011: | Train Loss: 0.510 | Train Acc: 79.797\n",
      "Epoch 012: | Train Loss: 0.502 | Train Acc: 80.113\n",
      "Epoch 013: | Train Loss: 0.497 | Train Acc: 80.238\n",
      "Epoch 014: | Train Loss: 0.493 | Train Acc: 80.393\n",
      "Epoch 015: | Train Loss: 0.490 | Train Acc: 80.793\n",
      "Epoch 016: | Train Loss: 0.482 | Train Acc: 80.796\n",
      "Epoch 017: | Train Loss: 0.480 | Train Acc: 80.914\n",
      "Epoch 018: | Train Loss: 0.476 | Train Acc: 81.073\n",
      "Epoch 019: | Train Loss: 0.472 | Train Acc: 81.214\n",
      "Epoch 020: | Train Loss: 0.468 | Train Acc: 81.392\n",
      "Epoch 021: | Train Loss: 0.466 | Train Acc: 81.294\n",
      "Epoch 022: | Train Loss: 0.462 | Train Acc: 81.749\n",
      "Epoch 023: | Train Loss: 0.459 | Train Acc: 81.563\n",
      "Epoch 024: | Train Loss: 0.457 | Train Acc: 81.742\n",
      "Epoch 025: | Train Loss: 0.454 | Train Acc: 81.797\n",
      "Epoch 026: | Train Loss: 0.450 | Train Acc: 81.807\n",
      "Epoch 027: | Train Loss: 0.447 | Train Acc: 82.008\n",
      "Epoch 028: | Train Loss: 0.446 | Train Acc: 82.129\n",
      "Epoch 029: | Train Loss: 0.443 | Train Acc: 82.177\n",
      "Epoch 030: | Train Loss: 0.440 | Train Acc: 82.346\n",
      "Epoch 031: | Train Loss: 0.439 | Train Acc: 82.451\n",
      "Epoch 032: | Train Loss: 0.438 | Train Acc: 82.399\n",
      "Epoch 033: | Train Loss: 0.431 | Train Acc: 82.566\n",
      "Epoch 034: | Train Loss: 0.431 | Train Acc: 82.670\n",
      "Epoch 035: | Train Loss: 0.427 | Train Acc: 82.643\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94cbdba65853445c854e2683b8071240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.753 | Train Acc: 72.670\n",
      "Epoch 002: | Train Loss: 0.620 | Train Acc: 76.561\n",
      "Epoch 003: | Train Loss: 0.591 | Train Acc: 77.266\n",
      "Epoch 004: | Train Loss: 0.570 | Train Acc: 77.883\n",
      "Epoch 005: | Train Loss: 0.558 | Train Acc: 78.307\n",
      "Epoch 006: | Train Loss: 0.545 | Train Acc: 78.842\n",
      "Epoch 007: | Train Loss: 0.538 | Train Acc: 79.071\n",
      "Epoch 008: | Train Loss: 0.526 | Train Acc: 79.608\n",
      "Epoch 009: | Train Loss: 0.521 | Train Acc: 79.512\n",
      "Epoch 010: | Train Loss: 0.513 | Train Acc: 79.813\n",
      "Epoch 011: | Train Loss: 0.506 | Train Acc: 79.871\n",
      "Epoch 012: | Train Loss: 0.502 | Train Acc: 80.203\n",
      "Epoch 013: | Train Loss: 0.496 | Train Acc: 80.506\n",
      "Epoch 014: | Train Loss: 0.491 | Train Acc: 80.728\n",
      "Epoch 015: | Train Loss: 0.489 | Train Acc: 80.705\n",
      "Epoch 016: | Train Loss: 0.485 | Train Acc: 80.836\n",
      "Epoch 017: | Train Loss: 0.481 | Train Acc: 80.807\n",
      "Epoch 018: | Train Loss: 0.474 | Train Acc: 81.143\n",
      "Epoch 019: | Train Loss: 0.473 | Train Acc: 81.327\n",
      "Epoch 020: | Train Loss: 0.468 | Train Acc: 81.458\n",
      "Epoch 021: | Train Loss: 0.465 | Train Acc: 81.437\n",
      "Epoch 022: | Train Loss: 0.462 | Train Acc: 81.571\n",
      "Epoch 023: | Train Loss: 0.460 | Train Acc: 81.532\n",
      "Epoch 024: | Train Loss: 0.455 | Train Acc: 81.725\n",
      "Epoch 025: | Train Loss: 0.450 | Train Acc: 81.924\n",
      "Epoch 026: | Train Loss: 0.449 | Train Acc: 81.962\n",
      "Epoch 027: | Train Loss: 0.446 | Train Acc: 82.049\n",
      "Epoch 028: | Train Loss: 0.443 | Train Acc: 82.073\n",
      "Epoch 029: | Train Loss: 0.441 | Train Acc: 82.227\n",
      "Epoch 030: | Train Loss: 0.440 | Train Acc: 82.379\n",
      "Epoch 031: | Train Loss: 0.437 | Train Acc: 82.420\n",
      "Epoch 032: | Train Loss: 0.436 | Train Acc: 82.563\n",
      "Epoch 033: | Train Loss: 0.431 | Train Acc: 82.667\n",
      "Epoch 034: | Train Loss: 0.430 | Train Acc: 82.649\n",
      "Epoch 035: | Train Loss: 0.428 | Train Acc: 82.678\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb05f81627214651a0516dd695a9b5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.753 | Train Acc: 72.617\n",
      "Epoch 002: | Train Loss: 0.624 | Train Acc: 76.204\n",
      "Epoch 003: | Train Loss: 0.592 | Train Acc: 77.165\n",
      "Epoch 004: | Train Loss: 0.572 | Train Acc: 77.874\n",
      "Epoch 005: | Train Loss: 0.559 | Train Acc: 78.267\n",
      "Epoch 006: | Train Loss: 0.548 | Train Acc: 78.648\n",
      "Epoch 007: | Train Loss: 0.537 | Train Acc: 79.125\n",
      "Epoch 008: | Train Loss: 0.528 | Train Acc: 79.269\n",
      "Epoch 009: | Train Loss: 0.521 | Train Acc: 79.605\n",
      "Epoch 010: | Train Loss: 0.515 | Train Acc: 79.785\n",
      "Epoch 011: | Train Loss: 0.506 | Train Acc: 79.896\n",
      "Epoch 012: | Train Loss: 0.504 | Train Acc: 80.253\n",
      "Epoch 013: | Train Loss: 0.498 | Train Acc: 80.297\n",
      "Epoch 014: | Train Loss: 0.492 | Train Acc: 80.575\n",
      "Epoch 015: | Train Loss: 0.488 | Train Acc: 80.722\n",
      "Epoch 016: | Train Loss: 0.480 | Train Acc: 80.990\n",
      "Epoch 017: | Train Loss: 0.477 | Train Acc: 81.023\n",
      "Epoch 018: | Train Loss: 0.475 | Train Acc: 80.977\n",
      "Epoch 019: | Train Loss: 0.472 | Train Acc: 81.175\n",
      "Epoch 020: | Train Loss: 0.469 | Train Acc: 81.222\n",
      "Epoch 021: | Train Loss: 0.464 | Train Acc: 81.442\n",
      "Epoch 022: | Train Loss: 0.463 | Train Acc: 81.591\n",
      "Epoch 023: | Train Loss: 0.459 | Train Acc: 81.727\n",
      "Epoch 024: | Train Loss: 0.455 | Train Acc: 81.714\n",
      "Epoch 025: | Train Loss: 0.453 | Train Acc: 81.881\n",
      "Epoch 026: | Train Loss: 0.451 | Train Acc: 82.107\n",
      "Epoch 027: | Train Loss: 0.449 | Train Acc: 82.135\n",
      "Epoch 028: | Train Loss: 0.445 | Train Acc: 82.134\n",
      "Epoch 029: | Train Loss: 0.443 | Train Acc: 82.205\n",
      "Epoch 030: | Train Loss: 0.438 | Train Acc: 82.266\n",
      "Epoch 031: | Train Loss: 0.438 | Train Acc: 82.237\n",
      "Epoch 032: | Train Loss: 0.438 | Train Acc: 82.393\n",
      "Epoch 033: | Train Loss: 0.431 | Train Acc: 82.645\n",
      "Epoch 034: | Train Loss: 0.433 | Train Acc: 82.492\n",
      "Epoch 035: | Train Loss: 0.430 | Train Acc: 82.736\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44bd0389a114db1927ed200c8d197d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.752 | Train Acc: 72.751\n",
      "Epoch 002: | Train Loss: 0.622 | Train Acc: 76.348\n",
      "Epoch 003: | Train Loss: 0.589 | Train Acc: 77.268\n",
      "Epoch 004: | Train Loss: 0.570 | Train Acc: 78.013\n",
      "Epoch 005: | Train Loss: 0.557 | Train Acc: 78.373\n",
      "Epoch 006: | Train Loss: 0.546 | Train Acc: 78.731\n",
      "Epoch 007: | Train Loss: 0.538 | Train Acc: 79.101\n",
      "Epoch 008: | Train Loss: 0.528 | Train Acc: 79.225\n",
      "Epoch 009: | Train Loss: 0.521 | Train Acc: 79.576\n",
      "Epoch 010: | Train Loss: 0.513 | Train Acc: 79.797\n",
      "Epoch 011: | Train Loss: 0.508 | Train Acc: 79.940\n",
      "Epoch 012: | Train Loss: 0.502 | Train Acc: 80.212\n",
      "Epoch 013: | Train Loss: 0.498 | Train Acc: 80.429\n",
      "Epoch 014: | Train Loss: 0.495 | Train Acc: 80.508\n",
      "Epoch 015: | Train Loss: 0.489 | Train Acc: 80.502\n",
      "Epoch 016: | Train Loss: 0.485 | Train Acc: 80.797\n",
      "Epoch 017: | Train Loss: 0.479 | Train Acc: 80.849\n",
      "Epoch 018: | Train Loss: 0.477 | Train Acc: 81.034\n",
      "Epoch 019: | Train Loss: 0.475 | Train Acc: 81.121\n",
      "Epoch 020: | Train Loss: 0.469 | Train Acc: 81.374\n",
      "Epoch 021: | Train Loss: 0.467 | Train Acc: 81.427\n",
      "Epoch 022: | Train Loss: 0.461 | Train Acc: 81.571\n",
      "Epoch 023: | Train Loss: 0.461 | Train Acc: 81.622\n",
      "Epoch 024: | Train Loss: 0.458 | Train Acc: 81.616\n",
      "Epoch 025: | Train Loss: 0.457 | Train Acc: 81.657\n",
      "Epoch 026: | Train Loss: 0.452 | Train Acc: 81.766\n",
      "Epoch 027: | Train Loss: 0.448 | Train Acc: 82.004\n",
      "Epoch 028: | Train Loss: 0.446 | Train Acc: 82.073\n",
      "Epoch 029: | Train Loss: 0.444 | Train Acc: 82.336\n",
      "Epoch 030: | Train Loss: 0.442 | Train Acc: 82.397\n",
      "Epoch 031: | Train Loss: 0.440 | Train Acc: 82.338\n",
      "Epoch 032: | Train Loss: 0.435 | Train Acc: 82.476\n",
      "Epoch 033: | Train Loss: 0.433 | Train Acc: 82.581\n",
      "Epoch 034: | Train Loss: 0.433 | Train Acc: 82.590\n",
      "Epoch 035: | Train Loss: 0.430 | Train Acc: 82.743\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06167c899e044a7a9a45778ea84a6776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.750 | Train Acc: 72.636\n",
      "Epoch 002: | Train Loss: 0.621 | Train Acc: 76.126\n",
      "Epoch 003: | Train Loss: 0.589 | Train Acc: 77.255\n",
      "Epoch 004: | Train Loss: 0.571 | Train Acc: 78.062\n",
      "Epoch 005: | Train Loss: 0.558 | Train Acc: 78.470\n",
      "Epoch 006: | Train Loss: 0.544 | Train Acc: 78.782\n",
      "Epoch 007: | Train Loss: 0.534 | Train Acc: 79.110\n",
      "Epoch 008: | Train Loss: 0.526 | Train Acc: 79.301\n",
      "Epoch 009: | Train Loss: 0.518 | Train Acc: 79.582\n",
      "Epoch 010: | Train Loss: 0.512 | Train Acc: 79.953\n",
      "Epoch 011: | Train Loss: 0.505 | Train Acc: 80.054\n",
      "Epoch 012: | Train Loss: 0.499 | Train Acc: 80.345\n",
      "Epoch 013: | Train Loss: 0.497 | Train Acc: 80.264\n",
      "Epoch 014: | Train Loss: 0.492 | Train Acc: 80.670\n",
      "Epoch 015: | Train Loss: 0.486 | Train Acc: 80.588\n",
      "Epoch 016: | Train Loss: 0.484 | Train Acc: 80.798\n",
      "Epoch 017: | Train Loss: 0.480 | Train Acc: 81.020\n",
      "Epoch 018: | Train Loss: 0.478 | Train Acc: 81.090\n",
      "Epoch 019: | Train Loss: 0.469 | Train Acc: 81.338\n",
      "Epoch 020: | Train Loss: 0.466 | Train Acc: 81.516\n",
      "Epoch 021: | Train Loss: 0.467 | Train Acc: 81.460\n",
      "Epoch 022: | Train Loss: 0.460 | Train Acc: 81.544\n",
      "Epoch 023: | Train Loss: 0.458 | Train Acc: 81.812\n",
      "Epoch 024: | Train Loss: 0.455 | Train Acc: 81.727\n",
      "Epoch 025: | Train Loss: 0.454 | Train Acc: 81.655\n",
      "Epoch 026: | Train Loss: 0.451 | Train Acc: 81.915\n",
      "Epoch 027: | Train Loss: 0.447 | Train Acc: 82.113\n",
      "Epoch 028: | Train Loss: 0.445 | Train Acc: 82.277\n",
      "Epoch 029: | Train Loss: 0.443 | Train Acc: 82.128\n",
      "Epoch 030: | Train Loss: 0.440 | Train Acc: 82.435\n",
      "Epoch 031: | Train Loss: 0.439 | Train Acc: 82.472\n",
      "Epoch 032: | Train Loss: 0.435 | Train Acc: 82.483\n",
      "Epoch 033: | Train Loss: 0.431 | Train Acc: 82.681\n",
      "Epoch 034: | Train Loss: 0.430 | Train Acc: 82.671\n",
      "Epoch 035: | Train Loss: 0.429 | Train Acc: 82.755\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94199680a5c547e09573fea2af29ea9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.753 | Train Acc: 72.347\n",
      "Epoch 002: | Train Loss: 0.623 | Train Acc: 76.176\n",
      "Epoch 003: | Train Loss: 0.595 | Train Acc: 77.100\n",
      "Epoch 004: | Train Loss: 0.574 | Train Acc: 77.658\n",
      "Epoch 005: | Train Loss: 0.557 | Train Acc: 78.241\n",
      "Epoch 006: | Train Loss: 0.547 | Train Acc: 78.751\n",
      "Epoch 007: | Train Loss: 0.536 | Train Acc: 79.093\n",
      "Epoch 008: | Train Loss: 0.529 | Train Acc: 79.180\n",
      "Epoch 009: | Train Loss: 0.521 | Train Acc: 79.525\n",
      "Epoch 010: | Train Loss: 0.514 | Train Acc: 79.730\n",
      "Epoch 011: | Train Loss: 0.509 | Train Acc: 80.010\n",
      "Epoch 012: | Train Loss: 0.503 | Train Acc: 80.209\n",
      "Epoch 013: | Train Loss: 0.499 | Train Acc: 80.176\n",
      "Epoch 014: | Train Loss: 0.491 | Train Acc: 80.525\n",
      "Epoch 015: | Train Loss: 0.490 | Train Acc: 80.519\n",
      "Epoch 016: | Train Loss: 0.481 | Train Acc: 80.905\n",
      "Epoch 017: | Train Loss: 0.481 | Train Acc: 80.858\n",
      "Epoch 018: | Train Loss: 0.476 | Train Acc: 81.013\n",
      "Epoch 019: | Train Loss: 0.473 | Train Acc: 81.250\n",
      "Epoch 020: | Train Loss: 0.470 | Train Acc: 81.168\n",
      "Epoch 021: | Train Loss: 0.467 | Train Acc: 81.369\n",
      "Epoch 022: | Train Loss: 0.463 | Train Acc: 81.516\n",
      "Epoch 023: | Train Loss: 0.459 | Train Acc: 81.547\n",
      "Epoch 024: | Train Loss: 0.454 | Train Acc: 81.952\n",
      "Epoch 025: | Train Loss: 0.454 | Train Acc: 81.806\n",
      "Epoch 026: | Train Loss: 0.451 | Train Acc: 81.851\n",
      "Epoch 027: | Train Loss: 0.448 | Train Acc: 82.047\n",
      "Epoch 028: | Train Loss: 0.444 | Train Acc: 82.269\n",
      "Epoch 029: | Train Loss: 0.442 | Train Acc: 82.486\n",
      "Epoch 030: | Train Loss: 0.441 | Train Acc: 82.289\n",
      "Epoch 031: | Train Loss: 0.440 | Train Acc: 82.493\n",
      "Epoch 032: | Train Loss: 0.436 | Train Acc: 82.566\n",
      "Epoch 033: | Train Loss: 0.432 | Train Acc: 82.522\n",
      "Epoch 034: | Train Loss: 0.430 | Train Acc: 82.644\n",
      "Epoch 035: | Train Loss: 0.429 | Train Acc: 82.756\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875f809cf94542118f473557486f7565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.753 | Train Acc: 72.615\n",
      "Epoch 002: | Train Loss: 0.623 | Train Acc: 76.260\n",
      "Epoch 003: | Train Loss: 0.595 | Train Acc: 77.141\n",
      "Epoch 004: | Train Loss: 0.572 | Train Acc: 77.734\n",
      "Epoch 005: | Train Loss: 0.557 | Train Acc: 78.489\n",
      "Epoch 006: | Train Loss: 0.546 | Train Acc: 78.820\n",
      "Epoch 007: | Train Loss: 0.537 | Train Acc: 79.024\n",
      "Epoch 008: | Train Loss: 0.530 | Train Acc: 79.218\n",
      "Epoch 009: | Train Loss: 0.521 | Train Acc: 79.539\n",
      "Epoch 010: | Train Loss: 0.514 | Train Acc: 79.727\n",
      "Epoch 011: | Train Loss: 0.511 | Train Acc: 79.816\n",
      "Epoch 012: | Train Loss: 0.503 | Train Acc: 80.176\n",
      "Epoch 013: | Train Loss: 0.495 | Train Acc: 80.289\n",
      "Epoch 014: | Train Loss: 0.494 | Train Acc: 80.509\n",
      "Epoch 015: | Train Loss: 0.488 | Train Acc: 80.689\n",
      "Epoch 016: | Train Loss: 0.487 | Train Acc: 80.813\n",
      "Epoch 017: | Train Loss: 0.481 | Train Acc: 80.909\n",
      "Epoch 018: | Train Loss: 0.474 | Train Acc: 81.025\n",
      "Epoch 019: | Train Loss: 0.472 | Train Acc: 81.167\n",
      "Epoch 020: | Train Loss: 0.470 | Train Acc: 81.397\n",
      "Epoch 021: | Train Loss: 0.466 | Train Acc: 81.484\n",
      "Epoch 022: | Train Loss: 0.464 | Train Acc: 81.541\n",
      "Epoch 023: | Train Loss: 0.459 | Train Acc: 81.586\n",
      "Epoch 024: | Train Loss: 0.457 | Train Acc: 81.672\n",
      "Epoch 025: | Train Loss: 0.452 | Train Acc: 81.853\n",
      "Epoch 026: | Train Loss: 0.451 | Train Acc: 81.793\n",
      "Epoch 027: | Train Loss: 0.450 | Train Acc: 82.007\n",
      "Epoch 028: | Train Loss: 0.446 | Train Acc: 82.087\n",
      "Epoch 029: | Train Loss: 0.445 | Train Acc: 82.087\n",
      "Epoch 030: | Train Loss: 0.441 | Train Acc: 82.223\n",
      "Epoch 031: | Train Loss: 0.441 | Train Acc: 82.139\n",
      "Epoch 032: | Train Loss: 0.437 | Train Acc: 82.282\n",
      "Epoch 033: | Train Loss: 0.437 | Train Acc: 82.383\n",
      "Epoch 034: | Train Loss: 0.433 | Train Acc: 82.499\n",
      "Epoch 035: | Train Loss: 0.429 | Train Acc: 82.704\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814d6390f0a145b78cee7380f4ef5ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.753 | Train Acc: 72.553\n",
      "Epoch 002: | Train Loss: 0.624 | Train Acc: 75.920\n",
      "Epoch 003: | Train Loss: 0.593 | Train Acc: 77.283\n",
      "Epoch 004: | Train Loss: 0.577 | Train Acc: 77.644\n",
      "Epoch 005: | Train Loss: 0.560 | Train Acc: 78.239\n",
      "Epoch 006: | Train Loss: 0.550 | Train Acc: 78.644\n",
      "Epoch 007: | Train Loss: 0.539 | Train Acc: 78.754\n",
      "Epoch 008: | Train Loss: 0.528 | Train Acc: 79.304\n",
      "Epoch 009: | Train Loss: 0.522 | Train Acc: 79.488\n",
      "Epoch 010: | Train Loss: 0.517 | Train Acc: 79.641\n",
      "Epoch 011: | Train Loss: 0.511 | Train Acc: 79.809\n",
      "Epoch 012: | Train Loss: 0.504 | Train Acc: 80.061\n",
      "Epoch 013: | Train Loss: 0.498 | Train Acc: 80.428\n",
      "Epoch 014: | Train Loss: 0.495 | Train Acc: 80.207\n",
      "Epoch 015: | Train Loss: 0.491 | Train Acc: 80.510\n",
      "Epoch 016: | Train Loss: 0.483 | Train Acc: 80.781\n",
      "Epoch 017: | Train Loss: 0.481 | Train Acc: 80.803\n",
      "Epoch 018: | Train Loss: 0.476 | Train Acc: 80.918\n",
      "Epoch 019: | Train Loss: 0.472 | Train Acc: 81.288\n",
      "Epoch 020: | Train Loss: 0.468 | Train Acc: 81.168\n",
      "Epoch 021: | Train Loss: 0.463 | Train Acc: 81.427\n",
      "Epoch 022: | Train Loss: 0.464 | Train Acc: 81.623\n",
      "Epoch 023: | Train Loss: 0.459 | Train Acc: 81.751\n",
      "Epoch 024: | Train Loss: 0.459 | Train Acc: 81.646\n",
      "Epoch 025: | Train Loss: 0.454 | Train Acc: 81.854\n",
      "Epoch 026: | Train Loss: 0.451 | Train Acc: 81.864\n",
      "Epoch 027: | Train Loss: 0.448 | Train Acc: 82.020\n",
      "Epoch 028: | Train Loss: 0.447 | Train Acc: 82.121\n",
      "Epoch 029: | Train Loss: 0.442 | Train Acc: 82.356\n",
      "Epoch 030: | Train Loss: 0.442 | Train Acc: 82.267\n",
      "Epoch 031: | Train Loss: 0.437 | Train Acc: 82.545\n",
      "Epoch 032: | Train Loss: 0.438 | Train Acc: 82.325\n",
      "Epoch 033: | Train Loss: 0.435 | Train Acc: 82.439\n",
      "Epoch 034: | Train Loss: 0.431 | Train Acc: 82.531\n",
      "Epoch 035: | Train Loss: 0.431 | Train Acc: 82.530\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7da476bfb24a26b2f6a9e8a71d6f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.746 | Train Acc: 72.790\n",
      "Epoch 002: | Train Loss: 0.623 | Train Acc: 76.239\n",
      "Epoch 003: | Train Loss: 0.592 | Train Acc: 77.243\n",
      "Epoch 004: | Train Loss: 0.571 | Train Acc: 77.873\n",
      "Epoch 005: | Train Loss: 0.557 | Train Acc: 78.334\n",
      "Epoch 006: | Train Loss: 0.548 | Train Acc: 78.702\n",
      "Epoch 007: | Train Loss: 0.537 | Train Acc: 78.986\n",
      "Epoch 008: | Train Loss: 0.530 | Train Acc: 79.223\n",
      "Epoch 009: | Train Loss: 0.520 | Train Acc: 79.622\n",
      "Epoch 010: | Train Loss: 0.513 | Train Acc: 79.933\n",
      "Epoch 011: | Train Loss: 0.508 | Train Acc: 80.001\n",
      "Epoch 012: | Train Loss: 0.502 | Train Acc: 80.215\n",
      "Epoch 013: | Train Loss: 0.499 | Train Acc: 80.306\n",
      "Epoch 014: | Train Loss: 0.495 | Train Acc: 80.411\n",
      "Epoch 015: | Train Loss: 0.489 | Train Acc: 80.616\n",
      "Epoch 016: | Train Loss: 0.484 | Train Acc: 80.814\n",
      "Epoch 017: | Train Loss: 0.481 | Train Acc: 80.797\n",
      "Epoch 018: | Train Loss: 0.475 | Train Acc: 81.228\n",
      "Epoch 019: | Train Loss: 0.473 | Train Acc: 81.359\n",
      "Epoch 020: | Train Loss: 0.469 | Train Acc: 81.438\n",
      "Epoch 021: | Train Loss: 0.469 | Train Acc: 81.334\n",
      "Epoch 022: | Train Loss: 0.462 | Train Acc: 81.526\n",
      "Epoch 023: | Train Loss: 0.458 | Train Acc: 81.666\n",
      "Epoch 024: | Train Loss: 0.455 | Train Acc: 81.945\n",
      "Epoch 025: | Train Loss: 0.453 | Train Acc: 81.966\n",
      "Epoch 026: | Train Loss: 0.448 | Train Acc: 82.088\n",
      "Epoch 027: | Train Loss: 0.447 | Train Acc: 82.066\n",
      "Epoch 028: | Train Loss: 0.447 | Train Acc: 82.199\n",
      "Epoch 029: | Train Loss: 0.443 | Train Acc: 82.274\n",
      "Epoch 030: | Train Loss: 0.440 | Train Acc: 82.366\n",
      "Epoch 031: | Train Loss: 0.434 | Train Acc: 82.509\n",
      "Epoch 032: | Train Loss: 0.435 | Train Acc: 82.493\n",
      "Epoch 033: | Train Loss: 0.435 | Train Acc: 82.595\n",
      "Epoch 034: | Train Loss: 0.431 | Train Acc: 82.572\n",
      "Epoch 035: | Train Loss: 0.428 | Train Acc: 82.827\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85cc09fd42849a593d1fc42f4eda630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.749 | Train Acc: 72.836\n",
      "Epoch 002: | Train Loss: 0.622 | Train Acc: 76.233\n",
      "Epoch 003: | Train Loss: 0.589 | Train Acc: 77.319\n",
      "Epoch 004: | Train Loss: 0.571 | Train Acc: 77.931\n",
      "Epoch 005: | Train Loss: 0.560 | Train Acc: 78.223\n",
      "Epoch 006: | Train Loss: 0.545 | Train Acc: 78.883\n",
      "Epoch 007: | Train Loss: 0.536 | Train Acc: 78.976\n",
      "Epoch 008: | Train Loss: 0.530 | Train Acc: 79.179\n",
      "Epoch 009: | Train Loss: 0.519 | Train Acc: 79.455\n",
      "Epoch 010: | Train Loss: 0.517 | Train Acc: 79.856\n",
      "Epoch 011: | Train Loss: 0.509 | Train Acc: 79.915\n",
      "Epoch 012: | Train Loss: 0.502 | Train Acc: 80.175\n",
      "Epoch 013: | Train Loss: 0.499 | Train Acc: 80.490\n",
      "Epoch 014: | Train Loss: 0.494 | Train Acc: 80.576\n",
      "Epoch 015: | Train Loss: 0.487 | Train Acc: 80.674\n",
      "Epoch 016: | Train Loss: 0.484 | Train Acc: 80.822\n",
      "Epoch 017: | Train Loss: 0.479 | Train Acc: 81.018\n",
      "Epoch 018: | Train Loss: 0.474 | Train Acc: 81.164\n",
      "Epoch 019: | Train Loss: 0.473 | Train Acc: 81.358\n",
      "Epoch 020: | Train Loss: 0.469 | Train Acc: 81.338\n",
      "Epoch 021: | Train Loss: 0.466 | Train Acc: 81.618\n",
      "Epoch 022: | Train Loss: 0.461 | Train Acc: 81.580\n",
      "Epoch 023: | Train Loss: 0.458 | Train Acc: 81.742\n",
      "Epoch 024: | Train Loss: 0.456 | Train Acc: 81.870\n",
      "Epoch 025: | Train Loss: 0.450 | Train Acc: 82.029\n",
      "Epoch 026: | Train Loss: 0.451 | Train Acc: 81.856\n",
      "Epoch 027: | Train Loss: 0.450 | Train Acc: 82.084\n",
      "Epoch 028: | Train Loss: 0.448 | Train Acc: 82.021\n",
      "Epoch 029: | Train Loss: 0.446 | Train Acc: 82.006\n",
      "Epoch 030: | Train Loss: 0.439 | Train Acc: 82.301\n",
      "Epoch 031: | Train Loss: 0.438 | Train Acc: 82.345\n",
      "Epoch 032: | Train Loss: 0.436 | Train Acc: 82.386\n",
      "Epoch 033: | Train Loss: 0.436 | Train Acc: 82.614\n",
      "Epoch 034: | Train Loss: 0.433 | Train Acc: 82.584\n",
      "Epoch 035: | Train Loss: 0.432 | Train Acc: 82.471\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c41a4531a2bd447790ab19ee1c88fadc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.755 | Train Acc: 72.618\n",
      "Epoch 002: | Train Loss: 0.621 | Train Acc: 76.312\n",
      "Epoch 003: | Train Loss: 0.591 | Train Acc: 77.319\n",
      "Epoch 004: | Train Loss: 0.571 | Train Acc: 77.846\n",
      "Epoch 005: | Train Loss: 0.560 | Train Acc: 78.289\n",
      "Epoch 006: | Train Loss: 0.545 | Train Acc: 78.659\n",
      "Epoch 007: | Train Loss: 0.537 | Train Acc: 78.906\n",
      "Epoch 008: | Train Loss: 0.528 | Train Acc: 79.184\n",
      "Epoch 009: | Train Loss: 0.522 | Train Acc: 79.671\n",
      "Epoch 010: | Train Loss: 0.516 | Train Acc: 79.731\n",
      "Epoch 011: | Train Loss: 0.508 | Train Acc: 80.009\n",
      "Epoch 012: | Train Loss: 0.501 | Train Acc: 80.172\n",
      "Epoch 013: | Train Loss: 0.499 | Train Acc: 80.287\n",
      "Epoch 014: | Train Loss: 0.494 | Train Acc: 80.430\n",
      "Epoch 015: | Train Loss: 0.487 | Train Acc: 80.721\n",
      "Epoch 016: | Train Loss: 0.483 | Train Acc: 80.692\n",
      "Epoch 017: | Train Loss: 0.477 | Train Acc: 80.920\n",
      "Epoch 018: | Train Loss: 0.476 | Train Acc: 80.948\n",
      "Epoch 019: | Train Loss: 0.474 | Train Acc: 81.139\n",
      "Epoch 020: | Train Loss: 0.468 | Train Acc: 81.365\n",
      "Epoch 021: | Train Loss: 0.466 | Train Acc: 81.370\n",
      "Epoch 022: | Train Loss: 0.463 | Train Acc: 81.550\n",
      "Epoch 023: | Train Loss: 0.462 | Train Acc: 81.537\n",
      "Epoch 024: | Train Loss: 0.456 | Train Acc: 81.733\n",
      "Epoch 025: | Train Loss: 0.453 | Train Acc: 81.651\n",
      "Epoch 026: | Train Loss: 0.451 | Train Acc: 81.917\n",
      "Epoch 027: | Train Loss: 0.449 | Train Acc: 81.927\n",
      "Epoch 028: | Train Loss: 0.446 | Train Acc: 82.046\n",
      "Epoch 029: | Train Loss: 0.442 | Train Acc: 82.141\n",
      "Epoch 030: | Train Loss: 0.442 | Train Acc: 82.243\n",
      "Epoch 031: | Train Loss: 0.438 | Train Acc: 82.416\n",
      "Epoch 032: | Train Loss: 0.436 | Train Acc: 82.377\n",
      "Epoch 033: | Train Loss: 0.433 | Train Acc: 82.615\n",
      "Epoch 034: | Train Loss: 0.432 | Train Acc: 82.555\n",
      "Epoch 035: | Train Loss: 0.432 | Train Acc: 82.722\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd20c7696d764a6db704f26b5a0c7e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.749 | Train Acc: 72.769\n",
      "Epoch 002: | Train Loss: 0.622 | Train Acc: 76.151\n",
      "Epoch 003: | Train Loss: 0.592 | Train Acc: 77.323\n",
      "Epoch 004: | Train Loss: 0.570 | Train Acc: 77.915\n",
      "Epoch 005: | Train Loss: 0.556 | Train Acc: 78.422\n",
      "Epoch 006: | Train Loss: 0.548 | Train Acc: 78.622\n",
      "Epoch 007: | Train Loss: 0.534 | Train Acc: 79.134\n",
      "Epoch 008: | Train Loss: 0.526 | Train Acc: 79.360\n",
      "Epoch 009: | Train Loss: 0.521 | Train Acc: 79.372\n",
      "Epoch 010: | Train Loss: 0.510 | Train Acc: 79.867\n",
      "Epoch 011: | Train Loss: 0.507 | Train Acc: 80.209\n",
      "Epoch 012: | Train Loss: 0.503 | Train Acc: 80.193\n",
      "Epoch 013: | Train Loss: 0.495 | Train Acc: 80.500\n",
      "Epoch 014: | Train Loss: 0.491 | Train Acc: 80.507\n",
      "Epoch 015: | Train Loss: 0.487 | Train Acc: 80.718\n",
      "Epoch 016: | Train Loss: 0.482 | Train Acc: 80.752\n",
      "Epoch 017: | Train Loss: 0.478 | Train Acc: 81.023\n",
      "Epoch 018: | Train Loss: 0.476 | Train Acc: 81.142\n",
      "Epoch 019: | Train Loss: 0.473 | Train Acc: 81.298\n",
      "Epoch 020: | Train Loss: 0.468 | Train Acc: 81.303\n",
      "Epoch 021: | Train Loss: 0.463 | Train Acc: 81.585\n",
      "Epoch 022: | Train Loss: 0.461 | Train Acc: 81.427\n",
      "Epoch 023: | Train Loss: 0.457 | Train Acc: 81.648\n",
      "Epoch 024: | Train Loss: 0.455 | Train Acc: 81.754\n",
      "Epoch 025: | Train Loss: 0.450 | Train Acc: 81.946\n",
      "Epoch 026: | Train Loss: 0.450 | Train Acc: 81.879\n",
      "Epoch 027: | Train Loss: 0.449 | Train Acc: 82.100\n",
      "Epoch 028: | Train Loss: 0.446 | Train Acc: 82.019\n",
      "Epoch 029: | Train Loss: 0.446 | Train Acc: 82.225\n",
      "Epoch 030: | Train Loss: 0.442 | Train Acc: 82.283\n",
      "Epoch 031: | Train Loss: 0.438 | Train Acc: 82.475\n",
      "Epoch 032: | Train Loss: 0.435 | Train Acc: 82.664\n",
      "Epoch 033: | Train Loss: 0.432 | Train Acc: 82.478\n",
      "Epoch 034: | Train Loss: 0.432 | Train Acc: 82.607\n",
      "Epoch 035: | Train Loss: 0.428 | Train Acc: 82.719\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2a576b3ec040fe93b0bf084b68fc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.751 | Train Acc: 72.727\n",
      "Epoch 002: | Train Loss: 0.624 | Train Acc: 76.194\n",
      "Epoch 003: | Train Loss: 0.592 | Train Acc: 77.242\n",
      "Epoch 004: | Train Loss: 0.570 | Train Acc: 78.077\n",
      "Epoch 005: | Train Loss: 0.559 | Train Acc: 78.345\n",
      "Epoch 006: | Train Loss: 0.547 | Train Acc: 78.738\n",
      "Epoch 007: | Train Loss: 0.539 | Train Acc: 78.931\n",
      "Epoch 008: | Train Loss: 0.529 | Train Acc: 79.339\n",
      "Epoch 009: | Train Loss: 0.523 | Train Acc: 79.570\n",
      "Epoch 010: | Train Loss: 0.515 | Train Acc: 79.735\n",
      "Epoch 011: | Train Loss: 0.508 | Train Acc: 80.035\n",
      "Epoch 012: | Train Loss: 0.503 | Train Acc: 80.199\n",
      "Epoch 013: | Train Loss: 0.500 | Train Acc: 80.234\n",
      "Epoch 014: | Train Loss: 0.492 | Train Acc: 80.394\n",
      "Epoch 015: | Train Loss: 0.488 | Train Acc: 80.714\n",
      "Epoch 016: | Train Loss: 0.484 | Train Acc: 80.655\n",
      "Epoch 017: | Train Loss: 0.482 | Train Acc: 80.824\n",
      "Epoch 018: | Train Loss: 0.479 | Train Acc: 80.945\n",
      "Epoch 019: | Train Loss: 0.473 | Train Acc: 81.177\n",
      "Epoch 020: | Train Loss: 0.471 | Train Acc: 81.169\n",
      "Epoch 021: | Train Loss: 0.465 | Train Acc: 81.451\n",
      "Epoch 022: | Train Loss: 0.463 | Train Acc: 81.419\n",
      "Epoch 023: | Train Loss: 0.457 | Train Acc: 81.711\n",
      "Epoch 024: | Train Loss: 0.457 | Train Acc: 81.821\n",
      "Epoch 025: | Train Loss: 0.454 | Train Acc: 82.060\n",
      "Epoch 026: | Train Loss: 0.453 | Train Acc: 81.987\n",
      "Epoch 027: | Train Loss: 0.448 | Train Acc: 82.113\n",
      "Epoch 028: | Train Loss: 0.445 | Train Acc: 82.028\n",
      "Epoch 029: | Train Loss: 0.443 | Train Acc: 82.255\n",
      "Epoch 030: | Train Loss: 0.441 | Train Acc: 82.377\n",
      "Epoch 031: | Train Loss: 0.440 | Train Acc: 82.441\n",
      "Epoch 032: | Train Loss: 0.437 | Train Acc: 82.367\n",
      "Epoch 033: | Train Loss: 0.434 | Train Acc: 82.514\n",
      "Epoch 034: | Train Loss: 0.431 | Train Acc: 82.542\n",
      "Epoch 035: | Train Loss: 0.428 | Train Acc: 82.557\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bb793c94f54c26a6a8b3fc890a5aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.749 | Train Acc: 72.800\n",
      "Epoch 002: | Train Loss: 0.620 | Train Acc: 76.494\n",
      "Epoch 003: | Train Loss: 0.592 | Train Acc: 77.169\n",
      "Epoch 004: | Train Loss: 0.572 | Train Acc: 78.111\n",
      "Epoch 005: | Train Loss: 0.558 | Train Acc: 78.360\n",
      "Epoch 006: | Train Loss: 0.547 | Train Acc: 78.623\n",
      "Epoch 007: | Train Loss: 0.537 | Train Acc: 79.050\n",
      "Epoch 008: | Train Loss: 0.528 | Train Acc: 79.371\n",
      "Epoch 009: | Train Loss: 0.520 | Train Acc: 79.525\n",
      "Epoch 010: | Train Loss: 0.512 | Train Acc: 79.903\n",
      "Epoch 011: | Train Loss: 0.507 | Train Acc: 79.994\n",
      "Epoch 012: | Train Loss: 0.504 | Train Acc: 80.150\n",
      "Epoch 013: | Train Loss: 0.495 | Train Acc: 80.547\n",
      "Epoch 014: | Train Loss: 0.493 | Train Acc: 80.402\n",
      "Epoch 015: | Train Loss: 0.488 | Train Acc: 80.788\n",
      "Epoch 016: | Train Loss: 0.484 | Train Acc: 80.730\n",
      "Epoch 017: | Train Loss: 0.480 | Train Acc: 80.994\n",
      "Epoch 018: | Train Loss: 0.475 | Train Acc: 81.137\n",
      "Epoch 019: | Train Loss: 0.474 | Train Acc: 81.160\n",
      "Epoch 020: | Train Loss: 0.470 | Train Acc: 81.279\n",
      "Epoch 021: | Train Loss: 0.464 | Train Acc: 81.436\n",
      "Epoch 022: | Train Loss: 0.463 | Train Acc: 81.523\n",
      "Epoch 023: | Train Loss: 0.460 | Train Acc: 81.747\n",
      "Epoch 024: | Train Loss: 0.456 | Train Acc: 81.807\n",
      "Epoch 025: | Train Loss: 0.452 | Train Acc: 81.883\n",
      "Epoch 026: | Train Loss: 0.451 | Train Acc: 82.040\n",
      "Epoch 027: | Train Loss: 0.447 | Train Acc: 82.157\n",
      "Epoch 028: | Train Loss: 0.448 | Train Acc: 82.072\n",
      "Epoch 029: | Train Loss: 0.441 | Train Acc: 82.162\n",
      "Epoch 030: | Train Loss: 0.440 | Train Acc: 82.211\n",
      "Epoch 031: | Train Loss: 0.439 | Train Acc: 82.293\n",
      "Epoch 032: | Train Loss: 0.436 | Train Acc: 82.555\n",
      "Epoch 033: | Train Loss: 0.434 | Train Acc: 82.630\n",
      "Epoch 034: | Train Loss: 0.430 | Train Acc: 82.607\n",
      "Epoch 035: | Train Loss: 0.428 | Train Acc: 82.984\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a56ee2eedef46e4aec87acb6e908a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.752 | Train Acc: 72.681\n",
      "Epoch 002: | Train Loss: 0.621 | Train Acc: 76.261\n",
      "Epoch 003: | Train Loss: 0.589 | Train Acc: 77.277\n",
      "Epoch 004: | Train Loss: 0.569 | Train Acc: 77.960\n",
      "Epoch 005: | Train Loss: 0.556 | Train Acc: 78.272\n",
      "Epoch 006: | Train Loss: 0.546 | Train Acc: 78.708\n",
      "Epoch 007: | Train Loss: 0.537 | Train Acc: 78.998\n",
      "Epoch 008: | Train Loss: 0.528 | Train Acc: 79.187\n",
      "Epoch 009: | Train Loss: 0.522 | Train Acc: 79.447\n",
      "Epoch 010: | Train Loss: 0.515 | Train Acc: 79.677\n",
      "Epoch 011: | Train Loss: 0.506 | Train Acc: 79.905\n",
      "Epoch 012: | Train Loss: 0.502 | Train Acc: 80.033\n",
      "Epoch 013: | Train Loss: 0.496 | Train Acc: 80.357\n",
      "Epoch 014: | Train Loss: 0.491 | Train Acc: 80.462\n",
      "Epoch 015: | Train Loss: 0.486 | Train Acc: 80.781\n",
      "Epoch 016: | Train Loss: 0.484 | Train Acc: 80.891\n",
      "Epoch 017: | Train Loss: 0.478 | Train Acc: 81.026\n",
      "Epoch 018: | Train Loss: 0.477 | Train Acc: 80.988\n",
      "Epoch 019: | Train Loss: 0.470 | Train Acc: 81.326\n",
      "Epoch 020: | Train Loss: 0.470 | Train Acc: 81.174\n",
      "Epoch 021: | Train Loss: 0.464 | Train Acc: 81.377\n",
      "Epoch 022: | Train Loss: 0.462 | Train Acc: 81.423\n",
      "Epoch 023: | Train Loss: 0.457 | Train Acc: 81.764\n",
      "Epoch 024: | Train Loss: 0.457 | Train Acc: 81.588\n",
      "Epoch 025: | Train Loss: 0.454 | Train Acc: 81.973\n",
      "Epoch 026: | Train Loss: 0.449 | Train Acc: 82.010\n",
      "Epoch 027: | Train Loss: 0.446 | Train Acc: 82.211\n",
      "Epoch 028: | Train Loss: 0.444 | Train Acc: 82.180\n",
      "Epoch 029: | Train Loss: 0.443 | Train Acc: 82.216\n",
      "Epoch 030: | Train Loss: 0.442 | Train Acc: 82.335\n",
      "Epoch 031: | Train Loss: 0.439 | Train Acc: 82.310\n",
      "Epoch 032: | Train Loss: 0.433 | Train Acc: 82.637\n",
      "Epoch 033: | Train Loss: 0.433 | Train Acc: 82.481\n",
      "Epoch 034: | Train Loss: 0.434 | Train Acc: 82.625\n",
      "Epoch 035: | Train Loss: 0.432 | Train Acc: 82.586\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d889a05ab59e4196aad111c09bde148d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.753 | Train Acc: 72.468\n",
      "Epoch 002: | Train Loss: 0.621 | Train Acc: 76.385\n",
      "Epoch 003: | Train Loss: 0.595 | Train Acc: 77.015\n",
      "Epoch 004: | Train Loss: 0.573 | Train Acc: 77.780\n",
      "Epoch 005: | Train Loss: 0.559 | Train Acc: 78.216\n",
      "Epoch 006: | Train Loss: 0.546 | Train Acc: 78.668\n",
      "Epoch 007: | Train Loss: 0.536 | Train Acc: 79.015\n",
      "Epoch 008: | Train Loss: 0.529 | Train Acc: 79.077\n",
      "Epoch 009: | Train Loss: 0.520 | Train Acc: 79.516\n",
      "Epoch 010: | Train Loss: 0.516 | Train Acc: 79.675\n",
      "Epoch 011: | Train Loss: 0.509 | Train Acc: 79.879\n",
      "Epoch 012: | Train Loss: 0.505 | Train Acc: 80.145\n",
      "Epoch 013: | Train Loss: 0.497 | Train Acc: 80.521\n",
      "Epoch 014: | Train Loss: 0.494 | Train Acc: 80.432\n",
      "Epoch 015: | Train Loss: 0.488 | Train Acc: 80.706\n",
      "Epoch 016: | Train Loss: 0.484 | Train Acc: 80.746\n",
      "Epoch 017: | Train Loss: 0.480 | Train Acc: 81.093\n",
      "Epoch 018: | Train Loss: 0.475 | Train Acc: 81.127\n",
      "Epoch 019: | Train Loss: 0.474 | Train Acc: 81.200\n",
      "Epoch 020: | Train Loss: 0.472 | Train Acc: 81.262\n",
      "Epoch 021: | Train Loss: 0.467 | Train Acc: 81.408\n",
      "Epoch 022: | Train Loss: 0.463 | Train Acc: 81.424\n",
      "Epoch 023: | Train Loss: 0.461 | Train Acc: 81.520\n",
      "Epoch 024: | Train Loss: 0.457 | Train Acc: 81.692\n",
      "Epoch 025: | Train Loss: 0.452 | Train Acc: 82.095\n",
      "Epoch 026: | Train Loss: 0.449 | Train Acc: 81.999\n",
      "Epoch 027: | Train Loss: 0.448 | Train Acc: 82.152\n",
      "Epoch 028: | Train Loss: 0.444 | Train Acc: 82.062\n",
      "Epoch 029: | Train Loss: 0.444 | Train Acc: 82.100\n",
      "Epoch 030: | Train Loss: 0.443 | Train Acc: 82.138\n",
      "Epoch 031: | Train Loss: 0.440 | Train Acc: 82.205\n",
      "Epoch 032: | Train Loss: 0.436 | Train Acc: 82.435\n",
      "Epoch 033: | Train Loss: 0.434 | Train Acc: 82.475\n",
      "Epoch 034: | Train Loss: 0.430 | Train Acc: 82.772\n",
      "Epoch 035: | Train Loss: 0.429 | Train Acc: 82.616\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3fda23b7e2445caaa406957b9fa3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.752 | Train Acc: 72.867\n",
      "Epoch 002: | Train Loss: 0.621 | Train Acc: 76.414\n",
      "Epoch 003: | Train Loss: 0.591 | Train Acc: 77.125\n",
      "Epoch 004: | Train Loss: 0.570 | Train Acc: 77.845\n",
      "Epoch 005: | Train Loss: 0.556 | Train Acc: 78.418\n",
      "Epoch 006: | Train Loss: 0.544 | Train Acc: 78.782\n",
      "Epoch 007: | Train Loss: 0.539 | Train Acc: 78.885\n",
      "Epoch 008: | Train Loss: 0.529 | Train Acc: 79.282\n",
      "Epoch 009: | Train Loss: 0.520 | Train Acc: 79.549\n",
      "Epoch 010: | Train Loss: 0.513 | Train Acc: 79.934\n",
      "Epoch 011: | Train Loss: 0.508 | Train Acc: 79.926\n",
      "Epoch 012: | Train Loss: 0.504 | Train Acc: 80.001\n",
      "Epoch 013: | Train Loss: 0.494 | Train Acc: 80.345\n",
      "Epoch 014: | Train Loss: 0.493 | Train Acc: 80.580\n",
      "Epoch 015: | Train Loss: 0.488 | Train Acc: 80.578\n",
      "Epoch 016: | Train Loss: 0.482 | Train Acc: 80.829\n",
      "Epoch 017: | Train Loss: 0.476 | Train Acc: 81.075\n",
      "Epoch 018: | Train Loss: 0.475 | Train Acc: 81.184\n",
      "Epoch 019: | Train Loss: 0.473 | Train Acc: 81.027\n",
      "Epoch 020: | Train Loss: 0.469 | Train Acc: 81.472\n",
      "Epoch 021: | Train Loss: 0.467 | Train Acc: 81.416\n",
      "Epoch 022: | Train Loss: 0.465 | Train Acc: 81.524\n",
      "Epoch 023: | Train Loss: 0.457 | Train Acc: 81.861\n",
      "Epoch 024: | Train Loss: 0.456 | Train Acc: 81.722\n",
      "Epoch 025: | Train Loss: 0.454 | Train Acc: 81.787\n",
      "Epoch 026: | Train Loss: 0.451 | Train Acc: 81.971\n",
      "Epoch 027: | Train Loss: 0.448 | Train Acc: 82.108\n",
      "Epoch 028: | Train Loss: 0.443 | Train Acc: 82.365\n",
      "Epoch 029: | Train Loss: 0.442 | Train Acc: 82.189\n",
      "Epoch 030: | Train Loss: 0.438 | Train Acc: 82.360\n",
      "Epoch 031: | Train Loss: 0.439 | Train Acc: 82.256\n",
      "Epoch 032: | Train Loss: 0.437 | Train Acc: 82.427\n",
      "Epoch 033: | Train Loss: 0.436 | Train Acc: 82.632\n",
      "Epoch 034: | Train Loss: 0.431 | Train Acc: 82.520\n",
      "Epoch 035: | Train Loss: 0.429 | Train Acc: 82.742\n",
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62092190ee164f18a527d0abb6f538e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.755 | Train Acc: 72.468\n",
      "Epoch 002: | Train Loss: 0.622 | Train Acc: 76.168\n",
      "Epoch 003: | Train Loss: 0.592 | Train Acc: 77.056\n",
      "Epoch 004: | Train Loss: 0.572 | Train Acc: 77.880\n",
      "Epoch 005: | Train Loss: 0.558 | Train Acc: 78.463\n",
      "Epoch 006: | Train Loss: 0.548 | Train Acc: 78.659\n",
      "Epoch 007: | Train Loss: 0.537 | Train Acc: 78.858\n",
      "Epoch 008: | Train Loss: 0.530 | Train Acc: 79.269\n",
      "Epoch 009: | Train Loss: 0.519 | Train Acc: 79.577\n",
      "Epoch 010: | Train Loss: 0.517 | Train Acc: 79.750\n",
      "Epoch 011: | Train Loss: 0.510 | Train Acc: 80.002\n",
      "Epoch 012: | Train Loss: 0.503 | Train Acc: 79.956\n",
      "Epoch 013: | Train Loss: 0.498 | Train Acc: 80.332\n",
      "Epoch 014: | Train Loss: 0.494 | Train Acc: 80.341\n",
      "Epoch 015: | Train Loss: 0.487 | Train Acc: 80.745\n",
      "Epoch 016: | Train Loss: 0.483 | Train Acc: 80.773\n",
      "Epoch 017: | Train Loss: 0.480 | Train Acc: 80.839\n",
      "Epoch 018: | Train Loss: 0.475 | Train Acc: 81.119\n",
      "Epoch 019: | Train Loss: 0.470 | Train Acc: 81.426\n",
      "Epoch 020: | Train Loss: 0.469 | Train Acc: 81.306\n",
      "Epoch 021: | Train Loss: 0.465 | Train Acc: 81.381\n",
      "Epoch 022: | Train Loss: 0.464 | Train Acc: 81.405\n",
      "Epoch 023: | Train Loss: 0.459 | Train Acc: 81.732\n",
      "Epoch 024: | Train Loss: 0.456 | Train Acc: 81.719\n",
      "Epoch 025: | Train Loss: 0.454 | Train Acc: 81.920\n",
      "Epoch 026: | Train Loss: 0.450 | Train Acc: 81.957\n",
      "Epoch 027: | Train Loss: 0.447 | Train Acc: 82.080\n",
      "Epoch 028: | Train Loss: 0.445 | Train Acc: 81.976\n",
      "Epoch 029: | Train Loss: 0.440 | Train Acc: 82.323\n",
      "Epoch 030: | Train Loss: 0.443 | Train Acc: 82.137\n",
      "Epoch 031: | Train Loss: 0.436 | Train Acc: 82.364\n",
      "Epoch 032: | Train Loss: 0.438 | Train Acc: 82.456\n",
      "Epoch 033: | Train Loss: 0.435 | Train Acc: 82.552\n",
      "Epoch 034: | Train Loss: 0.430 | Train Acc: 82.686\n",
      "Epoch 035: | Train Loss: 0.428 | Train Acc: 82.684\n"
     ]
    }
   ],
   "source": [
    "bag_n = 25\n",
    "NN_preds_list = []\n",
    "for bag in tqdm(range(1,bag_n+1)):\n",
    "    test_loader = DataLoader(dataset=test_dataset,\n",
    "                              batch_size=batch_size\n",
    "    )\n",
    "    ### Only for training on full dataset\n",
    "    train_loader = DataLoader(dataset=full_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle = True\n",
    "    )\n",
    "\n",
    "    class MulticlassClassification(nn.Module):\n",
    "        def __init__(self, num_feature, num_class):\n",
    "            super(MulticlassClassification, self).__init__()\n",
    "\n",
    "            self.layer_1 = nn.Linear(num_feature, 505)\n",
    "            self.layer_2 = nn.Linear(505, 152)\n",
    "            self.layer_out = nn.Linear(152, num_class) \n",
    "\n",
    "            self.relu = nn.ReLU()\n",
    "            self.dropout1 = nn.Dropout(p=0.38157117252594575)\n",
    "            self.dropout2 = nn.Dropout(p=0.20144716052206688)\n",
    "            self.batchnorm1 = nn.BatchNorm1d(505)\n",
    "            self.batchnorm2 = nn.BatchNorm1d(152)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.layer_1(x)\n",
    "            x = self.batchnorm1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout1(x)\n",
    "\n",
    "            x = self.layer_2(x)\n",
    "            x = self.batchnorm2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "\n",
    "            x = self.layer_out(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    model = MulticlassClassification(num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum = MOMENT)\n",
    "\n",
    "    def multi_acc(y_pred, y_test):\n",
    "        y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "        _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "\n",
    "        correct_pred = (y_pred_tags == y_test).float()\n",
    "        acc = correct_pred.sum() / len(correct_pred)\n",
    "        acc = acc * 100\n",
    "\n",
    "        return acc\n",
    "\n",
    "    def save_pred(y_pred, y_test):\n",
    "        y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "        _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "\n",
    "        return y_pred_tags, y_test\n",
    "\n",
    "    accuracy_stats = {\n",
    "        'train': [],\n",
    "        \"val\": []\n",
    "    }\n",
    "    loss_stats = {\n",
    "        'train': [],\n",
    "        \"val\": []\n",
    "    }\n",
    "\n",
    "    print(\"Begin training.\")\n",
    "    for e in tqdm(range(1, EPOCHS+1)):\n",
    "\n",
    "        # TRAINING\n",
    "        train_epoch_loss = 0\n",
    "        train_epoch_acc = 0\n",
    "\n",
    "        model.train()\n",
    "        for X_train_batch, y_train_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_train_pred = model(X_train_batch)\n",
    "\n",
    "            train_loss = criterion(y_train_pred, y_train_batch)\n",
    "            train_acc = multi_acc(y_train_pred, y_train_batch)\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_epoch_loss += train_loss.item()\n",
    "            train_epoch_acc += train_acc.item()\n",
    "\n",
    "        loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "        accuracy_stats['train'].append(train_epoch_acc/len(train_loader))                       \n",
    "\n",
    "        print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.3f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}')\n",
    "        \n",
    "    ### Prediction\n",
    "    y_pred_list = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X_batch, y_batch in test_loader: #in test_loader:\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred_prob = nn.functional.softmax(y_test_pred, dim = 1)\n",
    "            y_pred_list.append(y_test_pred_prob.numpy())\n",
    "\n",
    "    test_prediction = np.array(y_pred_list)\n",
    "    pred_df = pd.DataFrame(pd.DataFrame(np.concatenate(test_prediction)))\n",
    "    NN_prediction = pred_df.to_numpy()\n",
    "    NN_preds_list.append(NN_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_nn = 0\n",
    "for i in range(len(NN_preds_list)):\n",
    "        bag_nn += NN_preds_list[i]\n",
    "        \n",
    "bag_nn = bag_nn/len(NN_preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Class_3</th>\n",
       "      <th>Class_4</th>\n",
       "      <th>Class_5</th>\n",
       "      <th>Class_6</th>\n",
       "      <th>Class_7</th>\n",
       "      <th>Class_8</th>\n",
       "      <th>Class_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.266976e-05</td>\n",
       "      <td>1.782722e-01</td>\n",
       "      <td>1.723621e-01</td>\n",
       "      <td>6.464968e-01</td>\n",
       "      <td>4.904274e-07</td>\n",
       "      <td>2.575393e-06</td>\n",
       "      <td>2.840546e-03</td>\n",
       "      <td>1.787647e-06</td>\n",
       "      <td>9.686939e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.654512e-05</td>\n",
       "      <td>4.140747e-04</td>\n",
       "      <td>2.709027e-05</td>\n",
       "      <td>8.081172e-06</td>\n",
       "      <td>7.321881e-05</td>\n",
       "      <td>1.786772e-01</td>\n",
       "      <td>2.347893e-05</td>\n",
       "      <td>8.205765e-01</td>\n",
       "      <td>1.636986e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.924198e-09</td>\n",
       "      <td>1.114675e-10</td>\n",
       "      <td>7.176854e-12</td>\n",
       "      <td>1.114731e-09</td>\n",
       "      <td>6.597482e-11</td>\n",
       "      <td>9.999980e-01</td>\n",
       "      <td>5.494100e-09</td>\n",
       "      <td>2.067520e-06</td>\n",
       "      <td>1.159001e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.615727e-06</td>\n",
       "      <td>4.996934e-01</td>\n",
       "      <td>4.952756e-01</td>\n",
       "      <td>4.997120e-03</td>\n",
       "      <td>4.026070e-07</td>\n",
       "      <td>6.646044e-08</td>\n",
       "      <td>7.230842e-06</td>\n",
       "      <td>1.755419e-07</td>\n",
       "      <td>2.451029e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.630280e-01</td>\n",
       "      <td>4.056917e-06</td>\n",
       "      <td>8.249455e-07</td>\n",
       "      <td>3.784378e-07</td>\n",
       "      <td>4.295207e-07</td>\n",
       "      <td>4.266151e-04</td>\n",
       "      <td>1.251044e-04</td>\n",
       "      <td>2.323879e-02</td>\n",
       "      <td>7.131759e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144363</th>\n",
       "      <td>144364</td>\n",
       "      <td>2.194854e-01</td>\n",
       "      <td>3.312969e-03</td>\n",
       "      <td>5.323167e-04</td>\n",
       "      <td>8.635801e-03</td>\n",
       "      <td>3.967461e-04</td>\n",
       "      <td>6.970814e-01</td>\n",
       "      <td>2.403968e-02</td>\n",
       "      <td>1.638010e-02</td>\n",
       "      <td>3.013544e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144364</th>\n",
       "      <td>144365</td>\n",
       "      <td>3.430317e-04</td>\n",
       "      <td>3.178454e-01</td>\n",
       "      <td>5.453628e-01</td>\n",
       "      <td>9.104673e-02</td>\n",
       "      <td>1.552901e-04</td>\n",
       "      <td>2.503050e-04</td>\n",
       "      <td>4.494089e-02</td>\n",
       "      <td>3.115381e-05</td>\n",
       "      <td>2.445987e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144365</th>\n",
       "      <td>144366</td>\n",
       "      <td>9.126494e-06</td>\n",
       "      <td>5.553191e-01</td>\n",
       "      <td>3.363813e-01</td>\n",
       "      <td>1.038502e-01</td>\n",
       "      <td>3.504857e-06</td>\n",
       "      <td>1.051230e-04</td>\n",
       "      <td>4.309203e-03</td>\n",
       "      <td>1.835412e-05</td>\n",
       "      <td>4.035709e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144366</th>\n",
       "      <td>144367</td>\n",
       "      <td>9.332928e-05</td>\n",
       "      <td>4.642993e-01</td>\n",
       "      <td>3.020846e-02</td>\n",
       "      <td>5.050222e-01</td>\n",
       "      <td>2.225977e-05</td>\n",
       "      <td>1.080069e-05</td>\n",
       "      <td>3.318048e-04</td>\n",
       "      <td>7.976754e-06</td>\n",
       "      <td>3.871290e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144367</th>\n",
       "      <td>144368</td>\n",
       "      <td>4.576400e-05</td>\n",
       "      <td>4.782054e-01</td>\n",
       "      <td>4.605867e-01</td>\n",
       "      <td>3.156965e-02</td>\n",
       "      <td>1.864023e-05</td>\n",
       "      <td>2.212363e-04</td>\n",
       "      <td>2.933506e-02</td>\n",
       "      <td>1.091310e-05</td>\n",
       "      <td>6.559322e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144368 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id       Class_1       Class_2       Class_3       Class_4  \\\n",
       "0            1  2.266976e-05  1.782722e-01  1.723621e-01  6.464968e-01   \n",
       "1            2  3.654512e-05  4.140747e-04  2.709027e-05  8.081172e-06   \n",
       "2            3  2.924198e-09  1.114675e-10  7.176854e-12  1.114731e-09   \n",
       "3            4  1.615727e-06  4.996934e-01  4.952756e-01  4.997120e-03   \n",
       "4            5  2.630280e-01  4.056917e-06  8.249455e-07  3.784378e-07   \n",
       "...        ...           ...           ...           ...           ...   \n",
       "144363  144364  2.194854e-01  3.312969e-03  5.323167e-04  8.635801e-03   \n",
       "144364  144365  3.430317e-04  3.178454e-01  5.453628e-01  9.104673e-02   \n",
       "144365  144366  9.126494e-06  5.553191e-01  3.363813e-01  1.038502e-01   \n",
       "144366  144367  9.332928e-05  4.642993e-01  3.020846e-02  5.050222e-01   \n",
       "144367  144368  4.576400e-05  4.782054e-01  4.605867e-01  3.156965e-02   \n",
       "\n",
       "             Class_5       Class_6       Class_7       Class_8       Class_9  \n",
       "0       4.904274e-07  2.575393e-06  2.840546e-03  1.787647e-06  9.686939e-07  \n",
       "1       7.321881e-05  1.786772e-01  2.347893e-05  8.205765e-01  1.636986e-04  \n",
       "2       6.597482e-11  9.999980e-01  5.494100e-09  2.067520e-06  1.159001e-09  \n",
       "3       4.026070e-07  6.646044e-08  7.230842e-06  1.755419e-07  2.451029e-05  \n",
       "4       4.295207e-07  4.266151e-04  1.251044e-04  2.323879e-02  7.131759e-01  \n",
       "...              ...           ...           ...           ...           ...  \n",
       "144363  3.967461e-04  6.970814e-01  2.403968e-02  1.638010e-02  3.013544e-02  \n",
       "144364  1.552901e-04  2.503050e-04  4.494089e-02  3.115381e-05  2.445987e-05  \n",
       "144365  3.504857e-06  1.051230e-04  4.309203e-03  1.835412e-05  4.035709e-06  \n",
       "144366  2.225977e-05  1.080069e-05  3.318048e-04  7.976754e-06  3.871290e-06  \n",
       "144367  1.864023e-05  2.212363e-04  2.933506e-02  1.091310e-05  6.559322e-06  \n",
       "\n",
       "[144368 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_nn = pd.DataFrame(bag_nn)\n",
    "bag_nn.columns = ['Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9']\n",
    "bag_nn.insert(0,\"id\", test['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_nn.to_csv(f'~/Desktop/Data Science Projects/Otto Group /NN Predictions/NN_bag{len(NN_preds_list)}.csv',\n",
    "               header = True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining the 5 NN i made previously to this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag5 = pd.read_csv('~/Desktop/Data Science Projects/Otto Group /NN Predictions/NN_bag5.csv')\n",
    "bag5 = bag5.iloc[:,1:].to_numpy()\n",
    "bag5 = bag5*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag20 = pd.read_csv('~/Desktop/Data Science Projects/Otto Group /NN Predictions/NN_bag20.csv')\n",
    "bag20 = bag20.iloc[:,1:].to_numpy()\n",
    "bag20 = bag20*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag25 = (bag5+bag20)/25\n",
    "bag25 = pd.DataFrame(bag25)\n",
    "bag25.columns = ['Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9']\n",
    "bag25.insert(0,\"id\", test['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag25.to_csv(f'~/Desktop/Data Science Projects/Otto Group /NN Predictions/NN_bag{25}.csv',\n",
    "               header = True, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
